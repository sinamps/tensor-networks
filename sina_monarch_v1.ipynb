{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPKea9wu3TzYs9IX4xt2yr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c13cec10cb614ff58b4b39c4fd2a64dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5056e0359db467c821513c552ee45f7",
              "IPY_MODEL_4e7fe8118a8142c48e045e8e29fd2068",
              "IPY_MODEL_cb5d2dccb2214e8888b6232701b8c407"
            ],
            "layout": "IPY_MODEL_802945c22df04e87af84a9da53ade901"
          }
        },
        "c5056e0359db467c821513c552ee45f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_103ce3b6b75a4ec289c01460886594e5",
            "placeholder": "​",
            "style": "IPY_MODEL_191c85394f2a4b99a7f79a21e2eb6f24",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4e7fe8118a8142c48e045e8e29fd2068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f89268dfd0349909d1e007ad0cf6227",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4a860bed3b24cd59249367ac9119f4f",
            "value": 571
          }
        },
        "cb5d2dccb2214e8888b6232701b8c407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3aed7c4af6140b796ecbbefb721dc42",
            "placeholder": "​",
            "style": "IPY_MODEL_1f614ff3ea184a1da7f606e722755788",
            "value": " 571/571 [00:00&lt;00:00, 31.8kB/s]"
          }
        },
        "802945c22df04e87af84a9da53ade901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103ce3b6b75a4ec289c01460886594e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191c85394f2a4b99a7f79a21e2eb6f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f89268dfd0349909d1e007ad0cf6227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a860bed3b24cd59249367ac9119f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3aed7c4af6140b796ecbbefb721dc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f614ff3ea184a1da7f606e722755788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47db4299b4a14f199e7baac36755d057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60de4a9eb90143cb8346c11b88ed5bed",
              "IPY_MODEL_499bd57fc88a48788eb711b3141a3c1b",
              "IPY_MODEL_a5d4d96e19974adfade26b0f4d517906"
            ],
            "layout": "IPY_MODEL_c64bb2f687da4c2689f08e6f013b2f70"
          }
        },
        "60de4a9eb90143cb8346c11b88ed5bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8f682242c33494aa6ee5d2111be1612",
            "placeholder": "​",
            "style": "IPY_MODEL_c409c12e57924ff9a1f30b98603ed19d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "499bd57fc88a48788eb711b3141a3c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fcb71db5eac48d4b08efe994eb4bcb7",
            "max": 1344997306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_511ef6b720dd4c11a80d2f1e41f5eb18",
            "value": 1344997306
          }
        },
        "a5d4d96e19974adfade26b0f4d517906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e7bfbfdab542cc8368b2e74141f1b8",
            "placeholder": "​",
            "style": "IPY_MODEL_e54bc7d09c664c10ac2ab34271c22c31",
            "value": " 1.34G/1.34G [00:05&lt;00:00, 229MB/s]"
          }
        },
        "c64bb2f687da4c2689f08e6f013b2f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f682242c33494aa6ee5d2111be1612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c409c12e57924ff9a1f30b98603ed19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fcb71db5eac48d4b08efe994eb4bcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511ef6b720dd4c11a80d2f1e41f5eb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9e7bfbfdab542cc8368b2e74141f1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54bc7d09c664c10ac2ab34271c22c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinamps/tensor-networks/blob/main/sina_monarch_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is version 1. I am going to try the full matrix svd, full matrix svd with permutation, and block-wise svd, and block-wise svd with permutation, and finally monarch code for block-wise svd with permutation."
      ],
      "metadata": {
        "id": "QvoZrF7OYoAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch_pretrained_bert --upgrade\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCeE_PcoEXMc",
        "outputId": "b30a05eb-9af0-43fc-ed44-f0bc5a7bf25f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.22.4)\n",
            "Collecting boto3 (from pytorch_pretrained_bert)\n",
            "  Downloading boto3-1.26.131-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.65.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch_pretrained_bert) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch_pretrained_bert) (16.0.3)\n",
            "Collecting botocore<1.30.0,>=1.29.131 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading botocore-1.29.131-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.131->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.131->boto3->pytorch_pretrained_bert) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch_pretrained_bert\n",
            "Successfully installed boto3-1.26.131 botocore-1.29.131 jmespath-1.0.1 pytorch_pretrained_bert-0.6.2 s3transfer-0.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RGigVi06YeFr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoTokenizer, BertForPreTraining\n",
        "# from transformers import cached_path, WEIGHTS_NAME, TF2_WEIGHTS_NAME, TF_WEIGHTS_NAME \n",
        "# from transformers.file_utils import is_remote_url, hf_bucket_url\n",
        "import torch, os, sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "from einops import rearrange\n",
        "import math\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model = BertForPreTraining.from_pretrained(\"bert-large-uncased\")\n",
        "state_dict = model.state_dict()\n",
        "key_to_load = 'bert.encoder.layer.0.attention.self.query.weight'\n",
        "fixed_matrix = state_dict[key_to_load].to(device)\n",
        "fixed_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "c13cec10cb614ff58b4b39c4fd2a64dd",
            "c5056e0359db467c821513c552ee45f7",
            "4e7fe8118a8142c48e045e8e29fd2068",
            "cb5d2dccb2214e8888b6232701b8c407",
            "802945c22df04e87af84a9da53ade901",
            "103ce3b6b75a4ec289c01460886594e5",
            "191c85394f2a4b99a7f79a21e2eb6f24",
            "6f89268dfd0349909d1e007ad0cf6227",
            "e4a860bed3b24cd59249367ac9119f4f",
            "f3aed7c4af6140b796ecbbefb721dc42",
            "1f614ff3ea184a1da7f606e722755788",
            "47db4299b4a14f199e7baac36755d057",
            "60de4a9eb90143cb8346c11b88ed5bed",
            "499bd57fc88a48788eb711b3141a3c1b",
            "a5d4d96e19974adfade26b0f4d517906",
            "c64bb2f687da4c2689f08e6f013b2f70",
            "a8f682242c33494aa6ee5d2111be1612",
            "c409c12e57924ff9a1f30b98603ed19d",
            "3fcb71db5eac48d4b08efe994eb4bcb7",
            "511ef6b720dd4c11a80d2f1e41f5eb18",
            "d9e7bfbfdab542cc8368b2e74141f1b8",
            "e54bc7d09c664c10ac2ab34271c22c31"
          ]
        },
        "id": "ubmsMYWvZUaG",
        "outputId": "1030a1ad-2c67-42e6-b9d6-ae4ddb92d98d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c13cec10cb614ff58b4b39c4fd2a64dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47db4299b4a14f199e7baac36755d057"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_from_blocks(blocks):\n",
        "    \n",
        "    # blocks is a list of list of blocks\n",
        "    \n",
        "    block_size_x = blocks[0][0].shape[0]\n",
        "    block_size_y = blocks[0][0].shape[1]\n",
        "    \n",
        "    x_size = len(blocks)*block_size_x\n",
        "    y_size = len(blocks[0])*block_size_y\n",
        "    \n",
        "    new_matrix = torch.zeros((x_size, y_size))\n",
        "    \n",
        "    for i in range(len(blocks)):\n",
        "        x_index = i*block_size_x\n",
        "        for j in range(len(blocks[0])):\n",
        "            y_index = j*block_size_y\n",
        "            new_matrix[x_index:x_index+block_size_x,y_index:y_index + block_size_y] = blocks[i][j]\n",
        "    \n",
        "    return new_matrix\n",
        "\n",
        "\n",
        "def factors(n):\n",
        "    return [(i, n // i) for i in range(1, math.floor(math.sqrt(n)) + 1) if n % i == 0]\n",
        "\n",
        "\n",
        "def low_rank_project(M, rank):\n",
        "    \"\"\"Supports batches of matrices as well.\n",
        "    \"\"\"\n",
        "    U, S, Vt = torch.linalg.svd(M)\n",
        "    S_sqrt = S[..., :rank].sqrt()\n",
        "    U = U[..., :rank] * rearrange(S_sqrt, '... rank -> ... 1 rank')\n",
        "    Vt = rearrange(S_sqrt, '... rank -> ... rank 1') * Vt[..., :rank, :]\n",
        "    return U, Vt\n",
        "\n",
        "\n",
        "def calculate_all_norms(matrix_1, matrix_2):\n",
        "    \n",
        "#     frob = torch.norm(matrix_1.to(matrix_2.device) - matrix_2, p='fro')\n",
        "    difference_matrix = matrix_1.to(matrix_2.device) - matrix_2\n",
        "    \n",
        "    frob = torch.linalg.matrix_norm(difference_matrix, ord='fro')\n",
        "    \n",
        "    nuc = torch.linalg.matrix_norm(difference_matrix, ord='nuc')\n",
        "    \n",
        "    spectral = torch.linalg.matrix_norm(difference_matrix, ord=2)\n",
        "    \n",
        "    norms = {\n",
        "        'fro': frob,\n",
        "        'nuc': nuc,\n",
        "        'spectral': spectral,        \n",
        "    }\n",
        "    return norms"
      ],
      "metadata": {
        "id": "hdzYTjP7Zg3l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_svd(A, r):\n",
        "  \n",
        "    \"\"\"\n",
        "    Finds the two low-rank matrices of rank r from the matrix A.\n",
        "\n",
        "    Args:\n",
        "    A: The input matrix of size m*n.\n",
        "    r: The rank of the low-rank matrices.\n",
        "\n",
        "    Returns:\n",
        "    U: The first low-rank matrix of size m*r.\n",
        "    V: The second low-rank matrix of size r*n.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the singular value decomposition of A.\n",
        "    U, S, V = torch.linalg.svd(A)\n",
        "\n",
        "    # Keep the first r singular values and their corresponding singular vectors.\n",
        "    U = U[:, :r]\n",
        "    S = S[:r]\n",
        "    V = V[:r, :]\n",
        "\n",
        "    # Multiply U with S.\n",
        "    U = U @ S.diag()\n",
        "    \n",
        "    reconstructed = torch.matmul(U, V)\n",
        "#     print(U.shape, V.shape, reconstructed.shape)\n",
        "    # Return the two low-rank matrices.\n",
        "    return U, V, reconstructed"
      ],
      "metadata": {
        "id": "AfBDxUWzaVyQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "99b70a15"
      },
      "outputs": [],
      "source": [
        "def get_new_svd(A, r):\n",
        "  \n",
        "    \"\"\"\n",
        "    Finds the two low-rank matrices of rank r from the matrix A.\n",
        "\n",
        "    Args:\n",
        "    A: The input matrix of size m*n.\n",
        "    r: The rank of the low-rank matrices.\n",
        "\n",
        "    Returns:\n",
        "    U: The first low-rank matrix of size m*r.\n",
        "    V: The second low-rank matrix of size r*n.\n",
        "    \"\"\"\n",
        "    '''\n",
        "    # Get the singular value decomposition of A.\n",
        "    U, S, V = torch.linalg.svd(A)\n",
        "\n",
        "    # Keep the first r singular values and their corresponding singular vectors.\n",
        "    U = U[:, :r]\n",
        "    S = S[:r]\n",
        "    V = V[:r, :]\n",
        "\n",
        "    # Multiply U with S.\n",
        "    U = U @ S.diag()\n",
        "    \n",
        "    U = U.cdouble()\n",
        "    V = V.cdouble()\n",
        "    '''\n",
        "    U, V = low_rank_project(A, rank=r)\n",
        "    # Vp = rearrange(V, 'k r 1 s -> r k s')\n",
        "    Vp = rearrange(V, 'i j -> j i')\n",
        "    # Up = rearrange(U, 'k r s 1 -> k s r')\n",
        "    Up = rearrange(U, 'i j -> j i')\n",
        "    reconstructed = torch.matmul(Vp, Up)\n",
        "#     print(U.shape, V.shape, reconstructed.shape)\n",
        "    # Return the two low-rank matrices.\n",
        "    return Vp, Up, reconstructed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def blockdiag_butterfly_project(M, sizes=None):\n",
        "    \"\"\"Only works for square matrices for now\n",
        "    \"\"\"\n",
        "    m, n = M.shape\n",
        "    if m != n:\n",
        "        raise NotImplementedError('Only support square matrices')\n",
        "    if sizes is None:\n",
        "        # Find the factors that are closest to sqrt(n)\n",
        "        sizes = factors(n)[-1]\n",
        "        # Larger factor first is probably more efficient, idk\n",
        "        sizes = (sizes[1], sizes[0])\n",
        "    assert n == sizes[0] * sizes[1]\n",
        "    M_permuted_batched = rearrange(M, '(p k) (r s) -> k r p s', k=sizes[1], r=sizes[0])\n",
        "    U, Vt = low_rank_project(M_permuted_batched, rank=1)\n",
        "    w1_bfly = rearrange(Vt, 'k r 1 s -> r k s')\n",
        "    w2_bfly = rearrange(U, 'k r s 1 -> k s r')\n",
        "    return w1_bfly, w2_bfly"
      ],
      "metadata": {
        "id": "0TV-86nPak20"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlockdiagButterflyMultiply(torch.autograd.Function):\n",
        "\n",
        "    \"\"\"This is a faster implementation, with careful memory copies for the fastest\n",
        "    bmm performance.\n",
        "    The backward pass is also written manually with careful memory copies.\n",
        "    Arguments:\n",
        "        x: (batch, n)\n",
        "        w1_bfly: (k, q, p), where k = n / p\n",
        "        w2_bfly: (l, s, r), where l = k * q / r = n * q / (p * r)\n",
        "    Outputs:\n",
        "        out: (batch, m), where m = l * s = n * s * q / (p * r)\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float16)\n",
        "    def forward(ctx, x, w1_bfly, w2_bfly):\n",
        "        batch_shape, n = x.shape[:-1], x.shape[-1]\n",
        "        batch_dim = np.prod(batch_shape)\n",
        "        k, q, p = w1_bfly.shape\n",
        "        l, s, r = w2_bfly.shape\n",
        "        assert k * p == n\n",
        "        assert l * r == k * q\n",
        "        x_reshaped = x.reshape(batch_dim, k, p).transpose(0, 1)\n",
        "        out1 = torch.empty(batch_dim, k, q, device=x.device, dtype=x.dtype).transpose(0, 1)\n",
        "        out1 = torch.bmm(x_reshaped, w1_bfly.transpose(-1, -2), out=out1)\n",
        "        out1 = out1.transpose(0, 1).reshape(batch_dim, r, l).transpose(-1, -2).contiguous().transpose(0, 1)\n",
        "        out2 = torch.empty(batch_dim, l, s, device=x.device, dtype=x.dtype).transpose(0, 1)\n",
        "        out2 = torch.bmm(out1, w2_bfly.transpose(-1, -2), out=out2)\n",
        "        out2 = out2.permute(1, 2, 0).reshape(*batch_shape, s * l)\n",
        "        ctx.save_for_backward(x, w1_bfly, w2_bfly, out1)\n",
        "        return out2\n",
        "\n",
        "    @staticmethod\n",
        "    @torch.cuda.amp.custom_bwd\n",
        "    def backward(ctx, dout):\n",
        "        x, w1_bfly, w2_bfly, out1 = ctx.saved_tensors\n",
        "        batch_shape, n = x.shape[:-1], x.shape[-1]\n",
        "        batch_dim = np.prod(batch_shape)\n",
        "        k, q, p = w1_bfly.shape\n",
        "        l, s, r = w2_bfly.shape\n",
        "        # assert k * p == n\n",
        "        # assert l * r == k * q\n",
        "        dx, dw1_bfly, dw2_bfly = None, None, None\n",
        "        # dout_reshaped = dout.reshape(batch_dim, sqrtn, sqrtn).permute(2, 1, 0).contiguous()\n",
        "        dout_reshaped = dout.reshape(batch_dim, s, l).transpose(-1, -2).contiguous()\n",
        "        dout_reshaped = dout_reshaped.transpose(0, 1)\n",
        "        if ctx.needs_input_grad[2]:\n",
        "            # dw2_bfly = torch.empty(l, s, r, device=w2_bfly.device, dtype=w2_bfly.dtype)\n",
        "            # dw2_bfly = torch.bmm(dout_reshaped.transpose(-1, -2), out1, out=dw2_bfly)\n",
        "            dw2_bfly = torch.bmm(dout_reshaped.transpose(-1, -2), out1.conj())\n",
        "        if ctx.needs_input_grad[1] or ctx.needs_input_grad[0]:\n",
        "            dout1 = torch.empty(batch_dim, l, r, device=x.device, dtype=x.dtype).transpose(0, 1)\n",
        "            dout1 = torch.bmm(dout_reshaped, w2_bfly.conj(), out=dout1)\n",
        "            dout1 = dout1.transpose(0, 1).transpose(-1, -2).contiguous().reshape(batch_dim, k, q).transpose(0, 1)\n",
        "            # dout1 = dout1.permute(1, 2, 0).contiguous().transpose(0, 1)\n",
        "            if ctx.needs_input_grad[0]:\n",
        "                dx = torch.empty(batch_dim, k, p, device=x.device, dtype=x.dtype)\n",
        "                dx = torch.bmm(dout1, w1_bfly.conj(), out=dx.transpose(0, 1)).transpose(0, 1).reshape(*batch_shape, n)\n",
        "            if ctx.needs_input_grad[1]:\n",
        "                x_reshaped = x.reshape(batch_dim, k, p).transpose(0, 1)\n",
        "                dw1_bfly = torch.bmm(dout1.transpose(-1, -2), x_reshaped.conj())\n",
        "        return dx, dw1_bfly, dw2_bfly\n",
        "\n",
        "blockdiag_butterfly_multiply = BlockdiagButterflyMultiply.apply"
      ],
      "metadata": {
        "id": "DdXBZ_O5c7uX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code based on monarch's code to get L and R from monarch decomposition."
      ],
      "metadata": {
        "id": "2fWEgr09ipxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_monarch(fixed_matrix):\n",
        "    # set seed\n",
        "    # torch.random.manual_seed(0)\n",
        "    n = fixed_matrix.shape[1]\n",
        "    log_n = torch.log2(torch.tensor(n))\n",
        "    # n = 1 << log_n\n",
        "    log_n = int(log_n)\n",
        "    sqrtn = 1 << (log_n // 2)\n",
        "    batch_size = 1\n",
        "    eye = torch.eye(n, device=device)\n",
        "    # myweights = fixed_matrix.cfloat()\n",
        "    # transform = torch.fft.fft if direction == 'fft' else torch.fft.ifft\n",
        "    # dft = transform(eye, norm='ortho').t()\n",
        "    # dft = transform(myweights, norm='ortho').t()\n",
        "    # perm = bitreversal_permutation(n)\n",
        "    # We don't actually need the bitreversal permutation, any permutation that swap\n",
        "    # the axes of the sqrtn x sqrtn input will work.\n",
        "    perm = rearrange(torch.arange(n, device=device), '(i j) -> (j i)', i=sqrtn)\n",
        "    # The BP (butterfly - permutation) decomposition of FFT / iFFT\n",
        "    # Converting to complex128 makes the approximation an order of magnitude more accurate\n",
        "    w1_fft_projected, w2_fft_projected = blockdiag_butterfly_project(fixed_matrix[:, perm])\n",
        "    # w1_fft_projected, w2_fft_projected = w1_fft_projected.cfloat(), w2_fft_projected.cfloat()\n",
        "    recons = blockdiag_butterfly_multiply(eye, w1_fft_projected, w2_fft_projected)\n",
        "    # recons = torch.matmul(w1_fft_projected, w2_fft_projected).cfloat()\n",
        "    # fft_projected = blockdiag_butterfly_multiply(myweights, w1_fft_projected, w2_fft_projected).t()\n",
        "    # fft_projected = blockdiag_butterfly_multiply(myinput, w1_fft_projected, w2_fft_projected)\n",
        "    # fft_projected = torch.matmul(myweights_t, w1_fft_projected)\n",
        "    # fft_projected = torch.matmul(fft_projected, w2_fft_projected).t()\n",
        "    # print(\"shapes\")\n",
        "    # print(fft_projected.shape)\n",
        "    # print(myinput.shape)\n",
        "    # print(myinput[:, perm].shape)\n",
        "    # print(\"max abs difference:\", (fft_projected - myinput[:, perm]).abs().max())\n",
        "    # assert torch.allclose(fft_projected, dft[:, perm], rtol=1e-4, atol=1e-4)\n",
        "    # print(torch.norm(fft_projected - myinput[:, perm], p='fro'))\n",
        "    # return fft_projected\n",
        "    # x = torch.randn(batch_size, n, dtype=torch.complex64, device=\n",
        "    return w1_fft_projected, w2_fft_projected, recons"
      ],
      "metadata": {
        "id": "WGk1yV5m9Zr6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2d7fcaea"
      },
      "outputs": [],
      "source": [
        "def split_and_run_svd(fixed_matrix, block_size_x, block_size_y, rank, decomp):\n",
        "    \n",
        "    # Should return the full reconstructed matrix along with the block-wise low-rank decompositions\n",
        "    # x for rows, y for columns\n",
        "    # assuming that each index is perfectly divisible by the block sizes\n",
        "    \n",
        "    n_blocks_x = int(fixed_matrix.shape[0]/block_size_x)\n",
        "    n_blocks_y = int(fixed_matrix.shape[1]/block_size_y)\n",
        "    \n",
        "    print(f'Num Blocks in x (rows): {n_blocks_x}')\n",
        "    print(f'Num Blocks in y (cols): {n_blocks_y}')\n",
        "    \n",
        "    num_params = np.prod([n_blocks_x, n_blocks_y, (block_size_x+block_size_y)*rank])\n",
        "\n",
        "    print('Num parameters in the resulting decomposition ', num_params)\n",
        "    print('Num parameters in the original matrix ', fixed_matrix.shape[0]*fixed_matrix.shape[1])\n",
        "    \n",
        "    \n",
        "    # partition original matrix into blocks\n",
        "    \n",
        "    fixed_matrix_blocks = list()\n",
        "    # lmf_blocks = list()\n",
        "    for i in range(n_blocks_x):\n",
        "        x_index = i*block_size_x\n",
        "        column_block_list = []\n",
        "        for j in range(n_blocks_y):\n",
        "            y_index = j*block_size_y\n",
        "            block = fixed_matrix[x_index:x_index+block_size_x, y_index:y_index + block_size_y]\n",
        "            column_block_list.append(block)\n",
        "        fixed_matrix_blocks.append(column_block_list)\n",
        "    \n",
        "    low_ranks = list()\n",
        "    low_ranks_blocks = list() # reconstructed blocks from low-rank decompositions\n",
        "    \n",
        "    for i in range(len(fixed_matrix_blocks)):\n",
        "        low_ranks_cols = list()\n",
        "        low_ranks_cols_blocks = list()\n",
        "        \n",
        "        for j in range(len(fixed_matrix_blocks[0])):\n",
        "            if decomp == 'svd':\n",
        "              left, right, reconstructed = get_svd(fixed_matrix_blocks[i][j], rank)\n",
        "            elif decomp == 'svd_p':\n",
        "              left, right, reconstructed = get_new_svd(fixed_matrix_blocks[i][j], rank)\n",
        "            elif decomp == 'monarch':\n",
        "              left, right, reconstructed = get_monarch(fixed_matrix_blocks[i][j])\n",
        "            else:\n",
        "              raise Exception(\"No decomposition is specified!\")\n",
        "\n",
        "                \n",
        "            # left, right, reconstructed = get_monarch(fixed_matrix_blocks[i][j])\n",
        "\n",
        "#             left, right, reconstructed = get_sgd(fixed_matrix_blocks[i][j], rank)\n",
        "#             print(left.shape, right.shape, reconstructed.shape)\n",
        "            low_ranks_cols.append((left, right))\n",
        "            low_ranks_cols_blocks.append(reconstructed)\n",
        "#         print(f'{i+1}/{len(fixed_matrix_blocks)} done')\n",
        "        \n",
        "        low_ranks.append(low_ranks_cols)\n",
        "        low_ranks_blocks.append(low_ranks_cols_blocks)\n",
        "    return low_ranks, low_ranks_blocks, fixed_matrix_blocks, num_params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_rank_full_matrix_decomposition(fixed_matrix, desired_num_params):\n",
        "    \n",
        "    rank = int(desired_num_params / (fixed_matrix.shape[0] + fixed_matrix.shape[1]))\n",
        "    num_p = (fixed_matrix.shape[0] + fixed_matrix.shape[1])*rank\n",
        "    \n",
        "    print(f'Rank that gives parameters closest to {desired_num_params} is rank:{rank} with params: {num_p}')\n",
        "    \n",
        "    left, right, reconstructed = get_svd(fixed_matrix, rank)\n",
        "    \n",
        "    return left, right, reconstructed"
      ],
      "metadata": {
        "id": "LTNopuhigVld"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "id": "2a4bf393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac919fe8-a8ae-4503-ec0d-666d7cb525a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Blocks in x (rows): 32\n",
            "Num Blocks in y (cols): 32\n",
            "Num parameters in the resulting decomposition  65536\n",
            "Num parameters in the original matrix  1048576\n",
            "Num Blocks in x (rows): 32\n",
            "Num Blocks in y (cols): 32\n",
            "Num parameters in the resulting decomposition  65536\n",
            "Num parameters in the original matrix  1048576\n"
          ]
        }
      ],
      "source": [
        "svd_low_ranks, svd_low_ranks_blocks, svd_fixed_matrix_blocks, svd_num_params_block_svd = split_and_run_svd(fixed_matrix, block_size_x=32, block_size_y=32, rank=1, decomp='svd')\n",
        "ma_low_ranks, ma_low_ranks_blocks, ma_fixed_matrix_blocks, ma_num_params_block_svd = split_and_run_svd(fixed_matrix, block_size_x=32, block_size_y=32, rank=1, decomp='monarch')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perm = rearrange(torch.arange(1024, device=device), '(i j) -> (j i)', i=32)\n",
        "\n",
        "reconstructed_matrix_svd = reconstruct_from_blocks(svd_fixed_matrix_blocks)\n",
        "reconstructed_matrix_ma = reconstruct_from_blocks(svd_fixed_matrix_blocks)\n",
        "print(\"diff: reconstructed from blocks vs. original:\")\n",
        "print(torch.norm(reconstructed_matrix_svd.to(fixed_matrix.device) - fixed_matrix, p='fro'))\n",
        "assert torch.norm(reconstructed_matrix_svd.to(device) - reconstructed_matrix_ma.to(device), p='fro') == torch.tensor(0)\n",
        "print(\"\\n\")\n",
        "reconstructed_block_svd = reconstruct_from_blocks(svd_low_ranks_blocks)\n",
        "print(\"diff: reconstructed from low-rank svd blocks vs. original:\")\n",
        "print(torch.norm(reconstructed_block_svd.to(fixed_matrix.device) - fixed_matrix, p='fro'))\n",
        "print(\"\\n\")\n",
        "reconstructed_block_monarch = reconstruct_from_blocks(ma_low_ranks_blocks)\n",
        "print(\"diff: reconstructed from low-rank monarch blocks vs. original:\")\n",
        "print(torch.norm(reconstructed_block_monarch.to(fixed_matrix.device) - fixed_matrix[:, perm], p='fro'))\n",
        "print(\"\\n\")\n",
        "_, _, reconstructed_svd_full = find_closest_rank_full_matrix_decomposition(fixed_matrix, svd_num_params_block_svd)\n",
        "print(\"diff: reconstructed from full matrix svd vs. original:\")\n",
        "print(torch.norm(reconstructed_svd_full.to(fixed_matrix.device) - fixed_matrix, p='fro'))\n",
        "print(\"\\n\")\n",
        "_, _, reconstructed_monarch_full = get_monarch(fixed_matrix)\n",
        "print(\"diff: reconstructed from full matrix monarch vs. original:\")\n",
        "print(torch.norm(reconstructed_monarch_full.to(fixed_matrix.device) - fixed_matrix[:, perm], p='fro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqzqOsOwf4Cj",
        "outputId": "09873473-1309-490a-e0f8-122348f2b46b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff: reconstructed from blocks vs. original:\n",
            "tensor(0., device='cuda:0')\n",
            "\n",
            "\n",
            "diff: reconstructed from low-rank svd blocks vs. original:\n",
            "tensor(33.2463, device='cuda:0')\n",
            "\n",
            "\n",
            "diff: reconstructed from low-rank monarch blocks vs. original:\n",
            "tensor(44.6162, device='cuda:0')\n",
            "\n",
            "\n",
            "Rank that gives parameters closest to 65536 is rank:32 with params: 65536\n",
            "diff: reconstructed from full matrix svd vs. original:\n",
            "tensor(31.0410, device='cuda:0')\n",
            "\n",
            "\n",
            "diff: reconstructed from full matrix monarch vs. original:\n",
            "tensor(38.3040, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myinput = torch.rand(16, 1024).to(device)\n",
        "# assert torch.allclose(myrecons, fixed_matrix[:, perm].cfloat(), rtol=1e-4, atol=1e-4)\n",
        "true_res = torch.matmul(myinput, fixed_matrix.t())\n",
        "\n",
        "Vp, Up, svd_recons = get_new_svd(fixed_matrix, 1)\n",
        "tmp1 = torch.matmul(myinput, Vp)\n",
        "full_new_svd_res = torch.matmul(tmp1, Up[:, perm])\n",
        "print(torch.norm(full_new_svd_res - true_res, p='fro'))\n",
        "\n",
        "_, _, recons_fullsvd = get_svd(fixed_matrix, 1)\n",
        "full_svd_res = torch.matmul(myinput, recons_fullsvd)\n",
        "print(torch.norm(full_svd_res - true_res, p='fro'))\n",
        "\n",
        "L, R, ma_recons = get_monarch(fixed_matrix)\n",
        "monarch_res = blockdiag_butterfly_multiply(myinput, L, R)\n",
        "monarch_res_2 = torch.matmul(myinput, ma_recons)\n",
        "print(torch.norm(monarch_res - true_res, p='fro'))\n",
        "print(torch.norm(monarch_res_2 - true_res, p='fro'))\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "ysvd = torch.matmul(myinput, reconstructed_svd_full)\n",
        "print(torch.norm(ysvd - true_res, p='fro'))\n",
        "ymonarch = torch.matmul(myinput, reconstructed_monarch_full)\n",
        "print(torch.norm(ymonarch - true_res, p='fro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB5Pa7-gsLlH",
        "outputId": "236d3533-dcbb-4170-d2e7-c61022cceda3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(84.0075, device='cuda:0')\n",
            "tensor(81.0984, device='cuda:0')\n",
            "tensor(78.4225, device='cuda:0')\n",
            "tensor(78.4225, device='cuda:0')\n",
            "\n",
            "\n",
            "tensor(88.6976, device='cuda:0')\n",
            "tensor(78.4225, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_all_norms(reconstructed_matrix_svd, fixed_matrix))\n",
        "print(calculate_all_norms(reconstructed_svd_full, fixed_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk-kCkNcghQI",
        "outputId": "95c41977-2b57-4d63-e6fe-64bcf9f42b5b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fro': tensor(0., device='cuda:0'), 'nuc': tensor(0., device='cuda:0'), 'spectral': tensor(0., device='cuda:0')}\n",
            "{'fro': tensor(31.0410, device='cuda:0'), 'nuc': tensor(785.1836, device='cuda:0'), 'spectral': tensor(2.3623, device='cuda:0')}\n"
          ]
        }
      ]
    }
  ]
}